{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMoYJvByynIe",
        "colab_type": "code",
        "outputId": "240cb619-0e8a-4ad8-de22-67d5d7c5de9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!pip install fuzzywuzzy\n",
        "!git clone https://github.com/subha12k/data.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.17.0\n",
            "Cloning into 'data'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Total 7 (delta 0), reused 0 (delta 0), pack-reused 7\u001b[K\n",
            "Unpacking objects: 100% (7/7), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHeJhUXoyiY9",
        "colab_type": "code",
        "outputId": "97623cb3-ab92-4479-fe64-6a29ebd15868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# BLOCK 1 : Import Modules\n",
        "import os\n",
        "import time \n",
        "t1 = time.time()\n",
        "\n",
        "# Data Science imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualization Imports\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Utility Imports\n",
        "from fuzzywuzzy import fuzz\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C3dJDGkyiZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LARGE_DATASET = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7-iKoBNy51a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = os.path.join('/content', 'data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTlG4zkmyiZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BLOCK 2 : Read In Data And Sample A Few Movies\n",
        "\n",
        "if LARGE_DATASET is False:\n",
        "    \n",
        "    movies_filename = os.path.join(data_path, 'movies.csv')\n",
        "    ratings_filename = os.path.join(data_path, 'ratings.csv')\n",
        "    \n",
        "    movies_df = pd.read_csv(movies_filename,\n",
        "                        usecols=['movieId', 'title'],\n",
        "                        dtype={'movieId': 'int32', 'title': 'str'})\n",
        "\n",
        "    ratings_df = pd.read_csv(ratings_filename,\n",
        "                         usecols=['userId', 'movieId', 'rating'],\n",
        "                         dtype={'userId': 'int32', 'movieId': 'int32', 'rating': 'float32'})\n",
        "    \n",
        "else:   \n",
        "    movies_filename = './ml-10M100K/movies.dat'\n",
        "    ratings_filename = './ml-10M100K/ratings.dat'\n",
        "\n",
        "    movies = pd.read_csv(movies_filename,header=None,  sep = '::')\n",
        "    movies.columns = [\"movieId\", \"title\", \"genre\"]\n",
        "\n",
        "    ratings = pd.read_csv(ratings_filename,header=None,  sep = '::')\n",
        "    ratings.columns = [\"userId\", \"movieId\", \"rating\",\"dummy\"]\n",
        "\n",
        "\n",
        "    movies = movies[[\"movieId\",\"title\"]]\n",
        "    ratings_df = ratings[[\"userId\", \"movieId\", \"rating\"]]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhBaQkhIyiZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BLOCK 3: Write The Rating Matrix Builder And The ALSRecommender Class\n",
        "\n",
        "def get_rating_matrix(X):\n",
        "    \"\"\"Function to generate a ratings matrix and mappings for\n",
        "    the user and item ids to the row and column indices\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : pandas.DataFrame, shape=(n_ratings,>=3)\n",
        "        First 3 columns must be in order of user, item, rating.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    rating_matrix : 2d numpy array, shape=(n_users, n_items)\n",
        "    user_map : pandas Series, shape=(n_users,)\n",
        "        Mapping from the original user id to an integer in the range [0,n_users)\n",
        "    item_map : pandas Series, shape=(n_items,)\n",
        "        Mapping from the original item id to an integer in the range [0,n_items)\n",
        "    \"\"\"\n",
        "    user_col, item_col, rating_col = X.columns[:3]\n",
        "    rating = X[rating_col]\n",
        "    user_map = pd.Series(\n",
        "        index=np.unique(X[user_col]),\n",
        "        data=np.arange(X[user_col].nunique()),\n",
        "        name='user_map',\n",
        "    )\n",
        "    item_map = pd.Series(\n",
        "        index=np.unique(X[item_col]),\n",
        "        data=np.arange(X[item_col].nunique()),\n",
        "        name='columns_map',\n",
        "    )\n",
        "    user_inds = X[user_col].map(user_map)\n",
        "    item_inds = X[item_col].map(item_map)\n",
        "    rating_matrix = (\n",
        "        pd.pivot_table(\n",
        "            data=X,\n",
        "            values=rating_col,\n",
        "            index=user_inds,\n",
        "            columns=item_inds,\n",
        "        )\n",
        "        .fillna(0)\n",
        "        .values\n",
        "    )\n",
        "    return rating_matrix, user_map, item_map\n",
        "\n",
        "class ALSRecommender():\n",
        "    \"\"\"Recommender based on Alternating Least Squares algorithm.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    k : int, default=5\n",
        "        Number of latent features\n",
        "    lmbda : float, default=0.1\n",
        "        Regularization parameter\n",
        "    max_epochs : int, default=15\n",
        "        Max number of iterations to run\n",
        "    baseline_algo : object\n",
        "        Object with fit(X) and \n",
        "    \"\"\"\n",
        "    def __init__(self, k=5, lmbda=0.1, max_epochs=15, baseline_algo=None, error_metric='mae',\n",
        "                 verbose=True):\n",
        "        # Force integer in case it comes in as float\n",
        "        self.k = int(np.round(k))\n",
        "        self.lmbda = lmbda\n",
        "        self.max_epochs = max_epochs\n",
        "        self.baseline_algo = baseline_algo\n",
        "        self.error_metric = error_metric\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.U = None\n",
        "        self.I = None\n",
        "        self.initialized = False\n",
        "\n",
        "    def _calc_train_error(self, U, I, R, R_selector=None, error_metric='mae'):\n",
        "        if R_selector is None:\n",
        "            R_selector = (R > 0)\n",
        "        R_hat = np.dot(U.T, I)\n",
        "        if error_metric == 'mae':\n",
        "            error = np.sum(R_selector * np.abs(R_hat - R)) / np.sum(R_selector)\n",
        "        else:\n",
        "            raise ValueError(\"{} is an unsupported error metric\".format(metric))\n",
        "        return error\n",
        "\n",
        "    def _fit_init(self, X):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise ValueError(\"X must be a DataFrame\")\n",
        "        X = X.copy()\n",
        "        user_col, item_col, rating_col = X.columns[:3]\n",
        "        if self.baseline_algo is None:\n",
        "            self.train_mean = X[rating_col].mean()\n",
        "        else:\n",
        "            self.baseline_algo.fit(X)\n",
        "        self.R, self.user_map, self.item_map = get_rating_matrix(X)\n",
        "        n_users, n_items = self.R.shape\n",
        "        self.U = 3 * np.random.rand(self.k, n_users)\n",
        "        self.I = 3 * np.random.rand(self.k, n_items)\n",
        "        self.I[0, :] = self.R[self.R != 0].mean(axis=0) # Avg. rating for each movie\n",
        "        self.E = np.eye(self.k) # (k x k)-dimensional idendity matrix\n",
        "        self.epoch = 0\n",
        "        self.train_errors = []\n",
        "        self.initialized = True\n",
        "\n",
        "    def fit(self, X, n_epochs=None):\n",
        "        \"\"\"Fit model to training data X. If at least one iteration has already been run,\n",
        "        then the model will continue from its most recent state.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pandas DataFrame, shape=(n_ratings, >=3)\n",
        "            First 3 columns must correspond to user, item, and rating in that order\n",
        "        n_epochs : int, optional\n",
        "            Number of iterations to run. If not provided, will run for self.max_epochs\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self\n",
        "            This allows chaining like `ALSRecommender().fit(X_train).predict(X_test)`\n",
        "        \"\"\"\n",
        "        # Allow continuation from previous state if n_epochs is given. Otherwise start from scratch.\n",
        "        if n_epochs is None:\n",
        "            self.initialized = False\n",
        "        if not self.initialized:\n",
        "            self._fit_init(X)\n",
        "\n",
        "        epoch_0 = self.epoch\n",
        "        if n_epochs is None:\n",
        "            n_epochs = self.max_epochs - epoch_0\n",
        "\n",
        "        n_users, n_items = self.R.shape\n",
        "\n",
        "        # Run n_epochs iterations\n",
        "        for i_epoch in range(n_epochs):\n",
        "            if self.epoch >= self.max_epochs:\n",
        "                print(\"max_epochs = {}\".format(self.max_epochs))\n",
        "                break\n",
        "            # Fix I and estimate U\n",
        "            for i, Ri in enumerate(self.R):\n",
        "                nui = np.count_nonzero(Ri) # Number of items user i has rated\n",
        "                if (nui == 0): nui = 1 # Be aware of zero counts!\n",
        "                # Get array of nonzero indices in row Ii\n",
        "                Ri_nonzero_selector = np.nonzero(Ri)[0]\n",
        "                # Select subset of I associated with movies reviewed by user i\n",
        "                I_Ri = self.I[:, Ri_nonzero_selector]\n",
        "                # Select subset of row R_i associated with movies reviewed by user i\n",
        "                Ri_nonzero = self.R[i, Ri_nonzero_selector]\n",
        "                Ai = np.dot(I_Ri, I_Ri.T) + self.lmbda * nui * self.E\n",
        "                Vi = np.dot(I_Ri, Ri_nonzero.T)\n",
        "                self.U[:, i] = np.linalg.solve(Ai, Vi)\n",
        "            # Fix U and estimate I\n",
        "            for j, Rj in enumerate(self.R.T):\n",
        "                nmj = np.count_nonzero(Rj) # Number of users that rated item j\n",
        "                if (nmj == 0): nmj = 1 # Be aware of zero counts!\n",
        "                # Get array of nonzero indices in row Ij\n",
        "                Rj_nonzero_selector = np.nonzero(Rj)[0]\n",
        "                # Select subset of P associated with users who reviewed movie j\n",
        "                U_Rj = self.U[:, Rj_nonzero_selector]\n",
        "                # Select subset of column R_j associated with users who reviewed movie j\n",
        "                Rj_nonzero = self.R[Rj_nonzero_selector, j]\n",
        "                Aj = np.dot(U_Rj, U_Rj.T) + self.lmbda * nmj * self.E\n",
        "                Vj = np.dot(U_Rj, Rj_nonzero)\n",
        "                self.I[:, j] = np.linalg.solve(Aj, Vj)\n",
        "            error = self._calc_train_error(self.U, self.I, self.R)\n",
        "            self.train_errors.append(error)\n",
        "            if self.verbose:\n",
        "                print(\"[Epoch {}/{}] train error: {}\".format(self.epoch, self.max_epochs, error))\n",
        "            self.epoch += 1\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Generate predictions for user/item pairs\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pandas dataframe, shape = (n_pairs, 2)\n",
        "            User, item dataframe\n",
        "            \n",
        "        Returns\n",
        "        -------\n",
        "        rating_pred : 1d numpy array, shape = (n_pairs,)\n",
        "            Array of rating predictions for each user/item pair\n",
        "        \"\"\"\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise ValueError(\"X must be a DataFrame\")\n",
        "        X = X.copy()\n",
        "        user_col, item_col = X.columns[:2]\n",
        "        \n",
        "        if self.baseline_algo is None:\n",
        "            X['rating_baseline'] = self.train_mean\n",
        "        else:\n",
        "            X['rating_baseline'] = self.baseline_algo.predict(X)\n",
        "        X['rating'] = 0\n",
        "        known_user_and_item_mask = (\n",
        "            X[user_col].isin(self.user_map.index) & X[item_col].isin(self.item_map.index)\n",
        "        )\n",
        "        X_known, X_unknown = X[known_user_and_item_mask], X[~known_user_and_item_mask]\n",
        "        user_inds = X_known[user_col].map(self.user_map)\n",
        "        item_inds = X_known[item_col].map(self.item_map)\n",
        "        rating_pred = np.array([\n",
        "            np.sum(self.U[:, u_ind] * self.I[:, i_ind])\n",
        "            for u_ind, i_ind in zip(user_inds, item_inds)\n",
        "        ])\n",
        "        X.loc[known_user_and_item_mask, 'rating'] = rating_pred\n",
        "     \n",
        "        min_rating = np.min(self.R[np.nonzero(self.R)])\n",
        "        max_rating = np.max(self.R)\n",
        "        X.loc[X['rating'] < min_rating, 'rating'] = min_rating\n",
        "        X.loc[X['rating'] > max_rating, 'rating'] = max_rating\n",
        "        return X['rating'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9avQ2UByiZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BLOCK 4: Define The Make Recommender Function\n",
        "\n",
        "new_mat = ratings_df.pivot(index='movieId', columns='userId', values='rating').fillna(0)\n",
        "\n",
        "movie_to_idx = { movie: i for i,movie in \n",
        "    enumerate(list(movies_df.set_index('movieId').loc[new_mat.index].title))}\n",
        "\n",
        "def fuzzy_matching(mapper, fav_movie, verbose=True):\n",
        "    \"\"\"\n",
        "    return the closest match via fuzzy ratio. \n",
        "    \n",
        "    Parameters\n",
        "    ----------    \n",
        "       mapper:  dict, map movie title name to index of the movie in data\n",
        "    fav_movie:  str, movie name\n",
        "      verbose:  bool, print log if True\n",
        "\n",
        "       Return:  index of the closest match\n",
        "    \"\"\"\n",
        "    match_tuple = []\n",
        "    # get match\n",
        "    for title, idx in mapper.items():\n",
        "        ratio = fuzz.ratio(title.lower(), fav_movie.lower())\n",
        "        if ratio >= 60:\n",
        "            match_tuple.append((title, idx, ratio))\n",
        "    # sort\n",
        "    match_tuple = sorted(match_tuple, key=lambda x: x[2])[::-1]\n",
        "    if not match_tuple:\n",
        "        print('Oops! No match is found')\n",
        "        return\n",
        "    if verbose:\n",
        "        print('Found possible matches in our database: {0}\\n'.format([x[0] for x in match_tuple]))\n",
        "    return match_tuple[0][1]\n",
        "\n",
        "def get_movieId(movies_df, fav_movie_list):\n",
        "    \"\"\"\n",
        "    return movieId(s) of user's favorite movies\n",
        "\n",
        "    \"\"\"\n",
        "    movieId_list = []\n",
        "    \n",
        "    for movie in fav_movie_list:\n",
        "        movieId = fuzzy_matching(movie_to_idx, movie)\n",
        "        movieId_list.append(movieId)\n",
        "        \n",
        "    return(movieId_list)\n",
        "        \n",
        "def add_new_user_to_data(train_df, movieId_list):\n",
        "    \n",
        "    new_id = ratings_df[\"userId\"].max()+1\n",
        "            \n",
        "    max_rating = ratings_df[\"rating\"].max()\n",
        "    \n",
        "    user_rows = [[new_id, movieId, max_rating] for movieId in movieId_list]\n",
        "    \n",
        "    return(train_df.append((pd.DataFrame(user_rows, columns=['user','item','rating']))))\n",
        "    \n",
        "def recommend(model, train_df, movie_list, movies_df, pretrained=False, k=3):\n",
        "    \n",
        "    train_df = train_df.iloc[:, :3].copy()\n",
        "    train_df.columns = ['user', 'item', 'rating']\n",
        "    \n",
        "    movieId_list = get_movieId(movies_df, movie_list)\n",
        "    train_df = add_new_user_to_data(train_df, movieId_list)\n",
        "  \n",
        "    user = train_df[\"user\"].max()\n",
        "    \n",
        "    if not pretrained:\n",
        "        model.fit(train_df)\n",
        "        \n",
        "    train_df['pred'] = model.predict(train_df)\n",
        "    train_df = train_df.sort_values('pred', ascending=False)\n",
        "    recos = train_df[['item','pred']].drop_duplicates(subset=None, keep='first', inplace=False)\n",
        "    movies, preds = recos[['item', 'pred']].values[:10, :].T\n",
        "    \n",
        "    movies, preds = list(movies), list(preds)\n",
        "    \n",
        "    index = 0\n",
        "    for item in movies:\n",
        "        if item in movie_list:\n",
        "            movies.remove(item)\n",
        "            preds.remove(preds[movies.index(item)])\n",
        "            movies.append(recos[['item']].values[10+index, :].T)\n",
        "            preds.append(recos[['pred']].values[10+index, :].T)\n",
        "            index+=1\n",
        "\n",
        "    \n",
        "    return movies, preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSET7UqtyiZQ",
        "colab_type": "code",
        "outputId": "38330dc3-2485-420d-8ffa-f53b6299c2d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# BLOCK 5: Create The Dataset Splits\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "n_splits = 2\n",
        "skf = StratifiedKFold(n_splits=n_splits, random_state=0)\n",
        "splits = [\n",
        "    (train_inds, test_inds)\n",
        "    for train_inds, test_inds in skf.split(ratings_df, ratings_df['userId'])\n",
        "]\n",
        "\n",
        "train_inds, test_inds = splits[0]\n",
        "train_df, test_df = ratings_df.iloc[train_inds], ratings_df.iloc[test_inds]\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw4AvvCwyiZS",
        "colab_type": "code",
        "outputId": "33742f2e-dec0-4093-e67d-0cd622417b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# BLOCK 6: Train The Model \n",
        "model = ALSRecommender(k=20, lmbda=0.1, max_epochs=15, baseline_algo=None, verbose=False)\n",
        "movie_list = [\"Matrix The\"] \n",
        "movies, pred = recommend(model, train_df, movie_list, movies_df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found possible matches in our database: ['Matrix, The (1999)', 'Animatrix, The (2003)']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kN4LkeMyiZW",
        "colab_type": "code",
        "outputId": "9106e15d-e7e1-43db-f8ca-0a2b151670a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# BLOCK 7: Let's Recommend Movies\n",
        "\n",
        "for i,idx in enumerate(movies):\n",
        "        print('{0}: {1}'.format(i+1, (movies_df[movies_df.movieId==idx].title).values))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1: ['Forrest Gump (1994)']\n",
            "2: ['Finding Nemo (2003)']\n",
            "3: ['Dark Knight, The (2008)']\n",
            "4: ['Matrix, The (1999)']\n",
            "5: ['Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)']\n",
            "6: ['Fight Club (1999)']\n",
            "7: ['Shawshank Redemption, The (1994)']\n",
            "8: ['Love Actually (2003)']\n",
            "9: [\"Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\"]\n",
            "10: [\"Schindler's List (1993)\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZSffVtTyiZa",
        "colab_type": "code",
        "outputId": "6ae02058-e73f-4151-e396-957ac663eb19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(f'\\n Total time taken for the Recommender System to run is {time.time()-t1}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Total time taken for the Recommender System to run is 124.08367276191711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS-EdqsAyiZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}